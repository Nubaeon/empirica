{
  "finding_id": "5f13d8bb-f690-4cc2-b559-7cfbd4ad4103",
  "project_id": "748a81a2-ac14-45b8-a185-994997b76828",
  "session_id": "1dfb26ff-e28d-422a-998a-0213b92f6694",
  "ai_id": "claude-code",
  "created_at": "2026-02-08T11:11:53.553208+00:00",
  "finding": "Top embedding models for local deployment: Nomic Embed Text V2 (MoE, 305M active/475M total), Qwen3 Embedding (0.6B-32B variants, Apache 2.0), All-MiniLM-L6-v2 (5-14k sentences/sec on CPU). Ollama supports nomic-embed-text and mxbai-embed-large for offline deployment.",
  "impact": 0.8,
  "goal_id": "75f3fef2-f6cc-4c06-943b-7aa357fab591",
  "subtask_id": null,
  "subject": null,
  "finding_data": {
    "finding": "Top embedding models for local deployment: Nomic Embed Text V2 (MoE, 305M active/475M total), Qwen3 Embedding (0.6B-32B variants, Apache 2.0), All-MiniLM-L6-v2 (5-14k sentences/sec on CPU). Ollama supports nomic-embed-text and mxbai-embed-large for offline deployment.",
    "impact": 0.8
  }
}
