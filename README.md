# ğŸ§  Empirica - Functional Self-Awareness for AI Agents

> Epistemic transparency and calibration for high-stakes AI decision making

## What is Empirica?

AI agents assess their own knowledge, uncertainty, and capabilities *before* actingâ€”enabling principled decisions in critical domains where "I don't know" matters.

**This is empirically testable.** Functional self-awareness produces measurable results through calibration validation.

## Who Uses Empirica?

**ğŸ¤– AI agents** (Claude, GPT, Gemini, etc.) - You're the primary user  
**ğŸ‘¤ Developers** in critical domains - Healthcare, finance, research, engineering  
**ğŸ¢ Teams** requiring AI transparency - Audit trails, calibration metrics, decision logs

âš ï¸ **Not for casual use** - Requires genuine epistemic engagement

## Quick Start

### ğŸ¤– For AI Agents
```bash
empirica onboard --ai-id <your-name>
```
*10-minute interactive learning experience*

**Then:** [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md)

### ğŸ‘¤ For Human Developers
```bash
pip install -e .
empirica bootstrap --ai-id assistant
```

**Then:** [`docs/02_INSTALLATION.md`](docs/02_INSTALLATION.md) â†’ [`docs/03_CLI_QUICKSTART.md`](docs/03_CLI_QUICKSTART.md)

## Core Workflow

```
PREFLIGHT â†’ Assess what you know/don't know
    â†“
  ACT   â†’ Execute task with awareness
    â†“
POSTFLIGHT â†’ Calibrate: Were you overconfident? Underconfident?
```

**Example:**
```bash
# Before task: Assess your epistemic state
SESSION=$(empirica preflight "debug authentication issue" --quiet)

# Do the work...

# After task: Measure what you learned
empirica postflight $SESSION --summary "fixed OAuth token validation"

# System shows:
# - Epistemic delta (what you actually learned)
# - Calibration quality (predictions vs reality)
```

## Philosophy

**No heuristics.** No calibration shortcuts. No fake confidence scores.

Empirica helps AIs demonstrate *genuine epistemic self-awareness*:
- **What do I actually know?** (evidence-based)
- **What can I actually do?** (capabilities)
- **What am I uncertain about?** (unknowns)
- **What context am I missing?** (blind spots)

High uncertainty is **good** when appropriate. Acknowledge what you don't know.

## Key Features

- ğŸ¯ **12-vector epistemic self-assessment** - KNOW, DO, CONTEXT, CLARITY, COHERENCE, SIGNAL, DENSITY, STATE, CHANGE, COMPLETION, IMPACT, ENGAGEMENT (+ UNCERTAINTY meta-tracking)
- ğŸ”„ **CASCADE workflow** - Preflight â†’ Investigate â†’ Check â†’ Act â†’ Postflight â†’ Synthesize â†’ Learn
- ğŸ“Š **Calibration tracking** - Overconfident vs well-calibrated measurement
- ğŸ”Œ **MCP server** - IDE integration (Claude Desktop, Cursor, Windsurf, Rovo Dev)
- ğŸš **CLI interface** - Direct agent interaction via terminal
- ğŸ“ˆ **Dashboard monitoring** - Real-time epistemic tracking (tmux-based)
- ğŸ” **Bayesian belief tracking** - Detect calibration drift
- ğŸ“ **Session continuity** - Resume previous work with context

## Documentation

**Start here:**
- ğŸ¤– [AI Agent Quick Start](docs/01_a_AI_AGENT_START.md) - Command-line onboarding for AI agents
- ğŸ”Œ [MCP AI Start](docs/01_b_MCP_AI_START.md) - IDE integration (Claude Desktop, Cursor, etc.)

**Production guides:**
- ğŸš€ [Quick Start](docs/production/01_QUICK_START.md)
- ğŸ“¦ [Installation](docs/production/02_INSTALLATION.md)  
- ğŸ¯ [Basic Usage](docs/production/03_BASIC_USAGE.md)
- ğŸ—ï¸ [Architecture Overview](docs/production/04_ARCHITECTURE_OVERVIEW.md)

**Practical examples:**
- ğŸ” [Reasoning Reconstruction](examples/reasoning_reconstruction/) - Extract learning insights from sessions
- ğŸ“¦ [Knowledge Transfer](examples/reasoning_reconstruction/) - Share knowledge between AI agents
- âœ… Works today with core Empirica (no additional dependencies)

**See [`docs/`](docs/) and [`docs/production/`](docs/production/) for complete documentation.**

## Installation

```bash
# Clone repository
git clone https://github.com/your-org/empirica.git
cd empirica

# Install
pip install -e .

# Verify
empirica --version

# Start learning
empirica onboard --ai-id <your-name>
```

**Requirements:** Python 3.8+

**For MCP integration:** See [`docs/04_MCP_QUICKSTART.md`](docs/04_MCP_QUICKSTART.md)

## Example: Real Epistemic Assessment

```bash
# AI agent assesses task before starting
$ empirica preflight "refactor authentication module"

ğŸ“‹ Task: refactor authentication module
ğŸ§  Assessing epistemic state...

Vectors:
  KNOW:        0.75  (Proficient in auth patterns)
  DO:          0.65  (Can refactor with testing)
  CONTEXT:     0.55  (Need to see current implementation)
  UNCERTAINTY: 0.45  (Moderate - depends on tech stack)
  CLARITY:     0.80  (Clear goal, fuzzy scope)

âš ï¸  Recommendation: INVESTIGATE first (CONTEXT low)
ğŸ” Suggested actions:
   - Review current auth implementation
   - Check test coverage
   - Identify dependencies

Session: abc123 (saved)
```

After completing the work:

```bash
$ empirica postflight abc123 --summary "OAuth2 refactor complete"

ğŸ“Š Calibration Report:

Epistemic Delta:
  KNOW:    0.75 â†’ 0.85  (+0.10)  Learned OAuth2 edge cases
  DO:      0.65 â†’ 0.80  (+0.15)  Successful refactor
  CONTEXT: 0.55 â†’ 0.90  (+0.35)  Full codebase understanding

Calibration Quality: WELL-CALIBRATED âœ…
  - Predicted uncertainty matched actual learning
  - Appropriate investigation phase
  - Accurate capability assessment

Session saved with calibration metrics.
```

## Use Cases

### Critical Domain Decision Making
- Healthcare AI requiring "I don't know" acknowledgment
- Financial systems with audit requirements
- Research AI with epistemic rigor
- Engineering decisions with safety implications

### AI Transparency
- Show users what AI knows vs doesn't know
- Demonstrate genuine vs confabulated confidence
- Provide audit trails for AI decisions
- Track calibration over time

### Development Workflows
- Pre-task risk assessment
- Post-task learning measurement
- Investigation loop management
- Session continuity across interruptions

## Core Principles

âœ… **NO HEURISTICS** - Genuine self-assessment only  
âœ… **BE HONEST** - Acknowledge what you don't know  
âœ… **TRACK LEARNING** - Preflight â†’ postflight shows growth  
âœ… **VALIDATE CALIBRATION** - Were your predictions accurate?  
âœ… **EVIDENCE-BASED** - No pattern matching shortcuts

## License

[LICENSE TYPE] - See [LICENSE](LICENSE) file

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Support

- **ğŸ“– Documentation:** [`docs/README.md`](docs/README.md)
- **ğŸ”§ Troubleshooting:** [`docs/06_TROUBLESHOOTING.md`](docs/06_TROUBLESHOOTING.md)
- **ğŸ’¬ Questions:** Open an issue or ask your AI agent to run `empirica onboard`

---

**Questions?** Start with [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md) (AI) or [`docs/00_START_HERE.md`](docs/00_START_HERE.md) (Human)

## Enterprise & Research

**Reasoning Reconstruction (Available Now):**
- Extract epistemic learning from sessions
- Generate audit trails with temporal proofs
- Transfer knowledge between AI agents
- Privacy-preserving analysis options

See [`examples/reasoning_reconstruction/`](examples/reasoning_reconstruction/) for working scripts and documentation.

**Semantic Extension (Optional):**
- Vector embeddings for semantic search
- Multi-agent knowledge graphs
- Advanced decision reconstruction
- Enterprise-scale deployments

See [`docs/production/SEMANTIC_REASONING_EXTENSION.md`](docs/production/SEMANTIC_REASONING_EXTENSION.md) for architecture and roadmap.

**Key principle:** Core Empirica is complete. Semantic extension adds convenience, not capability.

