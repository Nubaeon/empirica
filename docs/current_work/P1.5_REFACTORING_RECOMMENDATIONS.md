# P1.5 Refactoring Recommendations

**Date:** 2025-11-19  
**Session:** 274757a9-1610-40ce-8919-d03193b15f70  
**Scope:** Code quality and architectural improvements discovered during validation

---

## Executive Summary

During the P1.5 multi-cascade validation session, several refactoring opportunities were identified through systematic testing of CLI commands, database operations, and documentation review. These recommendations are prioritized by impact and effort.

**Focus Areas:**
- Code consistency and standardization
- Documentation-code alignment
- Error handling improvements
- Database path management
- CLI command consistency

---

## High Priority Refactoring

### 1. Standardize CLI JSON Output Flag

**Issue:** Inconsistent JSON output support across commands

**Current State:**
```bash
# Some commands support --output json
empirica preflight --output json ✅
empirica check-submit --output json ✅

# Others don't
empirica sessions-list --output json ❌
empirica sessions-show --output json ❌
empirica checkpoint-list --output json ❌
```

**Impact:** 
- Inconsistent user experience
- Harder to script and automate
- Documentation confusion

**Recommendation:**
1. Add `--output json` flag to ALL commands
2. Standardize on `--output {default,json}` pattern
3. Ensure all JSON output is parseable

**Affected Files:**
- `empirica/cli/command_handlers/session_commands.py`
- `empirica/cli/command_handlers/checkpoint_commands.py`
- Any other command handlers missing JSON support

**Effort:** Medium (2-3 hours)  
**Priority:** HIGH  
**Impact:** User experience improvement

---

### 2. Fix CHECK Confidence Storage Bug

**Issue:** CHECK confidence values stored incorrectly (approximately half of input)

**Evidence:**
```
INPUT:  confidence=0.75  →  STORED: 0.35
INPUT:  confidence=0.80  →  STORED: 0.30
INPUT:  confidence=0.85  →  STORED: 0.35
```

**Root Cause Hypothesis:**
- Possible unit conversion issue (0-100 vs 0-1)
- Possible calculation error in command handler
- Possible database schema mismatch

**Investigation Steps:**
1. Review `empirica/cli/command_handlers/cascade_commands.py` (check-submit)
2. Check database insertion logic in `empirica/data/session_database.py`
3. Verify no transformation/calculation on confidence value
4. Add unit tests for confidence storage

**Recommendation:**
```python
# In check-submit handler, ensure:
def handle_check_submit(..., confidence: float):
    # NO transformations
    db.log_check_phase_assessment(
        confidence=confidence,  # Store as-is
        ...
    )
```

**Affected Files:**
- `empirica/cli/command_handlers/cascade_commands.py` (or assessment_commands.py)
- `empirica/data/session_database.py` (log_check_phase_assessment)

**Effort:** Low (1 hour investigation + fix)  
**Priority:** HIGH  
**Impact:** Data accuracy critical for calibration

---

### 3. Unify Database Path Configuration

**Issue:** Database path inconsistency between code and documentation

**Current Behavior:**
```python
# Code creates database at:
.empirica/sessions/sessions.db  # Project-relative

# Documentation claims:
~/.empirica/sessions.db  # Home directory
```

**User Impact:**
- Confusion about data location
- Difficulty finding session data
- Backup/restore confusion

**Recommendation (Option A - Preferred):**
Change code to use home directory by default:
```python
# In SessionDatabase.__init__:
if db_path is None:
    base_dir = Path.home() / '.empirica'  # Global location
    base_dir.mkdir(parents=True, exist_ok=True)
    db_path = base_dir / 'sessions.db'
```

**Recommendation (Option B):**
Update all documentation to reflect project-relative path:
```markdown
# Data Storage

Empirica stores session data in your project directory:
- **Database:** `.empirica/sessions/sessions.db`
- **Benefit:** Per-project isolation
- **Drawback:** Data not shared across projects
```

**Trade-offs:**
- **Option A:** Better for global session history, easier to find
- **Option B:** Better for project isolation, existing behavior

**Affected Files:**
- `empirica/data/session_database.py` (if Option A)
- All documentation files (if Option B)

**Effort:** Low (1 hour code change OR 2 hours doc updates)  
**Priority:** HIGH  
**Impact:** User experience and clarity

---

## Medium Priority Refactoring

### 4. Consolidate Import Paths

**Issue:** Mixed import patterns throughout codebase

**Current State:**
```python
# Some files use:
from empirica.core.metacognitive_cascade import MetacognitiveCascade

# Others might use:
from metacognitive_cascade.metacognitive_cascade import CanonicalEpistemicCascade

# Documentation uses:
from metacognitive_cascade.metacognitive_cascade import CanonicalEpistemicCascade
```

**Recommendation:**
1. Audit ALL Python files for import statements
2. Standardize on canonical import paths:
   ```python
   from empirica.core.metacognitive_cascade import MetacognitiveCascade
   from empirica.data.session_database import SessionDatabase
   from empirica.cli.cli_core import main
   ```
3. Update all documentation to match
4. Add pre-commit hook to enforce import conventions

**Affected Files:**
- All Python files (grep for old import patterns)
- All documentation with code examples

**Effort:** Medium (3-4 hours)  
**Priority:** MEDIUM  
**Impact:** Code consistency, documentation accuracy

---

### 5. Implement Cascade Counter in CLI Workflow

**Issue:** `total_cascades` field not incrementing in CLI workflow

**Current Behavior:**
```sql
-- After 3 cascades:
SELECT total_cascades FROM sessions WHERE session_id = '...';
-- Result: 0 (should be 3)
```

**Root Cause:**
- CLI workflow may bypass cascade creation
- Counter not updated on assessment submissions

**Recommendation:**
```python
# In preflight-submit or postflight-submit:
def handle_postflight_submit(...):
    db.log_postflight_assessment(...)
    
    # Increment cascade counter
    db.increment_cascade_count(session_id)
    
    return result
```

**Alternative:**
If cascade tracking not needed for CLI workflow, document this explicitly:
```markdown
## Cascade Tracking

The `total_cascades` counter is used by the Python API. 
CLI workflow uses assessment-based tracking instead.
```

**Affected Files:**
- `empirica/data/session_database.py` (add increment method)
- `empirica/cli/command_handlers/assessment_commands.py` (call increment)

**Effort:** Low (1-2 hours)  
**Priority:** MEDIUM  
**Impact:** Data completeness

---

### 6. Add cascade_id to CLI Assessments

**Issue:** All CLI assessments have `cascade_id=NULL`

**Current Behavior:**
```sql
SELECT cascade_id FROM preflight_assessments;
-- All NULL
```

**Impact:**
- No way to group assessments by cascade
- Harder to query "all assessments for CASCADE 2"

**Recommendation:**
```python
# Generate cascade_id on first assessment (PREFLIGHT)
def handle_preflight_submit(...):
    cascade_id = str(uuid.uuid4())  # Generate once per cascade
    
    db.log_preflight_assessment(
        session_id=session_id,
        cascade_id=cascade_id,  # Store for later use
        ...
    )
    
    # Return cascade_id for use in subsequent commands
    return {"cascade_id": cascade_id, ...}
```

**Challenge:** How to pass cascade_id between commands?
- Option 1: Return in response, user provides to next command
- Option 2: Store in local state file (`.empirica/current_cascade`)
- Option 3: Auto-detect most recent cascade for session

**Affected Files:**
- `empirica/cli/command_handlers/assessment_commands.py`
- `empirica/data/session_database.py`

**Effort:** Medium (2-3 hours)  
**Priority:** MEDIUM  
**Impact:** Data queryability

---

## Low Priority Refactoring

### 7. Add --version Flag

**Issue:** No version reporting

**Current Behavior:**
```bash
empirica --version
# Error: unrecognized arguments: --version
```

**Recommendation:**
```python
# In cli_core.py:
parser.add_argument(
    '--version',
    action='version',
    version=f'Empirica {get_version()}'
)

def get_version():
    # Read from __init__.py or pyproject.toml
    return "1.0.0"
```

**Affected Files:**
- `empirica/cli/cli_core.py`
- `empirica/__init__.py` (add __version__)

**Effort:** Very Low (30 minutes)  
**Priority:** LOW  
**Impact:** Developer experience

---

### 8. Improve Error Messages

**Issue:** Some error messages could be more helpful

**Examples:**
```bash
# Current:
empirica preflight-submit --session-id invalid
# Error: unrecognized arguments: --output json

# Better:
# Error: Invalid session ID format. Expected UUID or alias like 'latest:active:ai-id'
```

**Recommendation:**
- Add input validation with clear error messages
- Suggest corrections when possible
- Provide examples in error output

**Affected Files:**
- All command handlers
- `empirica/cli/cli_utils.py` (validation helpers)

**Effort:** Medium (2-3 hours)  
**Priority:** LOW  
**Impact:** User experience

---

### 9. Add Command Aliases

**Issue:** Some commands have long names

**Recommendation:**
```python
# Add aliases:
empirica pf       # preflight
empirica pf-sub   # preflight-submit
empirica check    # check (already short)
empirica pof      # postflight
empirica pof-sub  # postflight-submit
```

**Affected Files:**
- `empirica/cli/cli_core.py`

**Effort:** Low (1 hour)  
**Priority:** LOW  
**Impact:** Power user convenience

---

## Code Quality Improvements

### 10. Add Type Hints Throughout

**Current State:** Mixed type hint coverage

**Recommendation:**
```python
# Add type hints to all functions:
def handle_preflight_submit(
    session_id: str,
    vectors: Dict[str, float],
    reasoning: Optional[str] = None
) -> Dict[str, Any]:
    ...
```

**Benefits:**
- Better IDE support
- Catch type errors early
- Improved documentation

**Effort:** High (8-10 hours for full codebase)  
**Priority:** LOW  
**Impact:** Developer experience, code quality

---

### 11. Add Docstrings to All Public Functions

**Current State:** Some functions lack docstrings

**Recommendation:**
```python
def log_preflight_assessment(
    self,
    session_id: str,
    cascade_id: Optional[str],
    prompt_summary: str,
    vectors: Dict[str, float],
    uncertainty_notes: str = ""
) -> str:
    """Store preflight epistemic assessment.
    
    Args:
        session_id: Session identifier
        cascade_id: Optional cascade identifier
        prompt_summary: Task description
        vectors: 13 epistemic vectors (0.0 to 1.0)
        uncertainty_notes: Optional notes about uncertainty
        
    Returns:
        assessment_id: Unique identifier for this assessment
        
    Raises:
        ValueError: If vectors are out of range [0, 1]
    """
    ...
```

**Effort:** High (8-10 hours)  
**Priority:** LOW  
**Impact:** Code maintainability

---

## Architecture Improvements

### 12. Extract Configuration Management

**Issue:** Configuration scattered across files

**Current State:**
```python
# Database path in session_database.py
# MCP config in mcp.json
# Bootstrap levels in bootstrap_commands.py
```

**Recommendation:**
Create centralized config:
```python
# empirica/config/settings.py
from pathlib import Path
from typing import Optional

class EmpiricaConfig:
    def __init__(self, config_path: Optional[Path] = None):
        self.database_path = self._get_database_path()
        self.mcp_enabled = self._get_mcp_config()
        self.bootstrap_level = 2  # default
        
    def _get_database_path(self) -> Path:
        # Centralized logic for database path
        return Path.home() / '.empirica' / 'sessions.db'
```

**Affected Files:**
- New: `empirica/config/settings.py`
- Update: `empirica/data/session_database.py`
- Update: All command handlers

**Effort:** Medium (4-5 hours)  
**Priority:** LOW  
**Impact:** Code organization, testability

---

## Testing Improvements

### 13. Add Integration Tests for Multi-Cascade Sessions

**Current State:** No automated tests for multi-cascade workflows

**Recommendation:**
```python
# tests/integration/test_multi_cascade_session.py
def test_three_cascade_session():
    """Test session continuity across 3 cascades"""
    session_id = create_session()
    
    # CASCADE 1
    preflight_1 = submit_preflight(session_id, ...)
    check_1 = submit_check(session_id, ...)
    postflight_1 = submit_postflight(session_id, ...)
    
    # CASCADE 2
    preflight_2 = submit_preflight(session_id, ...)
    check_2 = submit_check(session_id, ...)
    postflight_2 = submit_postflight(session_id, ...)
    
    # CASCADE 3
    preflight_3 = submit_preflight(session_id, ...)
    check_3 = submit_check(session_id, ...)
    postflight_3 = submit_postflight(session_id, ...)
    
    # Validate
    assert_learning_progression(session_id)
    assert_no_data_loss(session_id)
```

**Effort:** Medium (3-4 hours)  
**Priority:** MEDIUM  
**Impact:** Regression prevention

---

### 14. Add CLI Command Tests

**Current State:** Manual testing only

**Recommendation:**
```python
# tests/cli/test_commands.py
def test_preflight_json_output():
    """Test preflight --output json returns valid JSON"""
    result = run_cli(['preflight', 'task', '--prompt-only', '--output', 'json'])
    data = json.loads(result.stdout)
    assert 'session_id' in data
    assert 'assessment_id' in data
```

**Effort:** High (6-8 hours for comprehensive coverage)  
**Priority:** MEDIUM  
**Impact:** Confidence in releases

---

## Documentation Improvements

### 15. Create CLI Command Reference

**Missing:** Comprehensive CLI documentation

**Recommendation:**
Create `docs/production/CLI_COMMAND_REFERENCE.md`:
```markdown
# CLI Command Reference

## Core Workflow Commands

### preflight
Execute preflight epistemic assessment.

**Usage:**
```bash
empirica preflight <task> --session-id <id> [--prompt-only] [--output json]
```

**Arguments:**
- `task` - Task description (required)
- `--session-id` - Session identifier (required)
- `--prompt-only` - Return prompt without LLM call (optional)
- `--output json` - Output as JSON (optional)

**Example:**
```bash
empirica preflight "Audit CLI commands" \
  --session-id abc-123 \
  --prompt-only \
  --output json
```
...
```

**Effort:** Medium (3-4 hours)  
**Priority:** HIGH (part of doc fixes)  
**Impact:** User success

---

## Summary Tables

### Priority Breakdown

| Priority | Count | Total Effort |
|----------|-------|--------------|
| HIGH | 3 | 5-8 hours |
| MEDIUM | 6 | 15-20 hours |
| LOW | 6 | 20-25 hours |
| **TOTAL** | **15** | **40-53 hours** |

### Impact Breakdown

| Impact Area | Recommendations | Effort |
|-------------|-----------------|--------|
| User Experience | 7 | 15-20 hours |
| Data Accuracy | 3 | 8-10 hours |
| Code Quality | 5 | 25-30 hours |
| **TOTAL** | **15** | **48-60 hours** |

---

## Recommended Implementation Order

### Sprint 1: Critical Fixes (Week 1)
1. Fix CHECK confidence bug (1 hour) ← CRITICAL
2. Add JSON output to session commands (2-3 hours)
3. Unify database path (1-2 hours)

**Total:** 4-6 hours

### Sprint 2: Documentation (Week 1)
4. Fix documentation import paths (2-3 hours)
5. Create CLI command reference (3-4 hours)
6. Document database path (1 hour)

**Total:** 6-8 hours

### Sprint 3: Data Completeness (Week 2)
7. Implement cascade counter (1-2 hours)
8. Add cascade_id tracking (2-3 hours)
9. Add integration tests (3-4 hours)

**Total:** 6-9 hours

### Sprint 4: Polish (Week 2)
10. Add --version flag (30 minutes)
11. Improve error messages (2-3 hours)
12. Add command aliases (1 hour)

**Total:** 3.5-4.5 hours

### Sprint 5: Long-term (Future)
13. Add type hints (8-10 hours)
14. Add docstrings (8-10 hours)
15. Extract configuration (4-5 hours)

**Total:** 20-25 hours

---

## Conclusion

**Total Identified Issues:** 15 refactoring opportunities  
**High Priority:** 3 (must fix before release)  
**Medium Priority:** 6 (should fix soon)  
**Low Priority:** 6 (nice to have)

**Immediate Action Items (Before Release):**
1. Fix CHECK confidence bug
2. Add JSON output to all commands
3. Resolve database path inconsistency
4. Fix documentation import paths

**Estimated Time to Production Ready:** 10-14 hours

**Confidence in Recommendations:** 0.90/1.0

---

**Analyzed By:** RovoDev  
**Session:** P1.5 Full System Validation  
**Date:** 2025-11-19
